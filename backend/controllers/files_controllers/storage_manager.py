# controllers/files_controllers/storage_manager.py
import os
import json
import glob
from typing import Dict, Any, Optional
import pandas as pd

class FileStorageManager:
    def __init__(self):
        self.data_cache: Dict[str, pd.DataFrame] = {}
        
        # âœ… USAR RUTA ABSOLUTA
        self.upload_dir = os.path.abspath("uploads")
        self.storage_file = os.path.join(self.upload_dir, "files_info.json")
        
        print(f"ðŸ“ Directorio uploads: {self.upload_dir}")
        print(f"ðŸ“„ Archivo storage: {self.storage_file}")
        
        # âœ… CARGAR Y SINCRONIZAR AL INICIALIZAR
        self._load_and_sync_storage()
    
    def _get_existing_files(self):
        """Obtiene todos los archivos fÃ­sicos realmente presentes"""
        if not os.path.exists(self.upload_dir):
            return set()
        
        # Buscar archivos con extensiones vÃ¡lidas
        pattern = os.path.join(self.upload_dir, "*")
        files = glob.glob(pattern)
        
        # Extraer solo los IDs de archivos vÃ¡lidos
        valid_extensions = {'.csv', '.xlsx', '.xls'}
        existing_ids = set()
        
        for file_path in files:
            filename = os.path.basename(file_path)
            if filename == 'files_info.json':
                continue
            
            name, ext = os.path.splitext(filename)
            if ext.lower() in valid_extensions:
                existing_ids.add(name)
        
        return existing_ids
    
    def _load_and_sync_storage(self):
        """Carga y sincroniza el storage con archivos fÃ­sicos"""
        try:
            # âœ… OBTENER ARCHIVOS REALES
            existing_file_ids = self._get_existing_files()
            print(f"ðŸ“‚ Archivos fÃ­sicos encontrados: {len(existing_file_ids)} - {list(existing_file_ids)}")
            
            # âœ… CARGAR JSON SI EXISTE
            if os.path.exists(self.storage_file):
                with open(self.storage_file, 'r', encoding='utf-8') as f:
                    json_data = json.load(f)
                print(f"ðŸ“¥ JSON cargado: {len(json_data)} entradas")
                
                # âœ… SINCRONIZAR: Solo mantener archivos que existen fÃ­sicamente
                synced_storage = {}
                for file_id, file_info in json_data.items():
                    if file_id in existing_file_ids:
                        # Verificar doble que el archivo fÃ­sico existe
                        file_path = file_info.get("path", "")
                        if file_path and os.path.exists(file_path):
                            synced_storage[file_id] = file_info
                        else:
                            print(f"âš ï¸ JSON tiene entrada pero archivo no existe: {file_info.get('original_name', file_id)}")
                    else:
                        print(f"ðŸ—‘ï¸ Eliminando del JSON archivo inexistente: {file_info.get('original_name', file_id)}")
                
                self.storage = synced_storage
                
                # âœ… GUARDAR JSON SINCRONIZADO
                if len(synced_storage) != len(json_data):
                    print(f"ðŸ”„ Sincronizando JSON: {len(json_data)} â†’ {len(synced_storage)} entradas")
                    self._save_storage()
                
            else:
                print("ðŸ“ JSON no existe, inicializando storage vacÃ­o")
                self.storage = {}
            
            print(f"âœ… Storage sincronizado: {len(self.storage)} archivos vÃ¡lidos")
            if self.storage:
                print(f"ðŸ“‹ IDs disponibles: {list(self.storage.keys())}")
                
        except Exception as e:
            print(f"âŒ Error sincronizando storage: {e}")
            self.storage = {}
    
    def _save_storage(self):
        """Guarda el storage en archivo JSON"""
        try:
            self.ensure_upload_directory()
            with open(self.storage_file, 'w', encoding='utf-8') as f:
                json.dump(self.storage, f, indent=2, ensure_ascii=False)
            print(f"ðŸ’¾ Storage guardado: {len(self.storage)} archivos")
        except Exception as e:
            print(f"âŒ Error guardando storage: {e}")
    
    def ensure_upload_directory(self) -> str:
        """Asegura que el directorio de uploads exista"""
        if not os.path.exists(self.upload_dir):
            os.makedirs(self.upload_dir, exist_ok=True)
            print(f"ðŸ“ Directorio creado: {self.upload_dir}")
        return self.upload_dir
    
    def store_file_info(self, file_id: str, file_info: Dict[str, Any]):
        """Almacena informaciÃ³n del archivo de forma persistente"""
        file_path = file_info.get("path", "")
        if file_path and os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            file_info["file_size"] = file_size
            file_info["stored_at"] = pd.Timestamp.now().isoformat()
            print(f"âœ… Archivo almacenado: {file_info.get('original_name')} ({file_size:,} bytes)")
        
        self.storage[file_id] = file_info
        self._save_storage()
        print(f"ðŸ“Š Storage actualizado: {len(self.storage)} archivos totales")
    
    def get_file_info(self, file_id: str) -> Optional[Dict[str, Any]]:
        """Obtiene informaciÃ³n del archivo con auto-sincronizaciÃ³n"""
        
        # âœ… RECARGAR Y SINCRONIZAR SI STORAGE ESTÃ VACÃO
        if not self.storage:
            print(f"âš ï¸ Storage vacÃ­o, recargando y sincronizando...")
            self._load_and_sync_storage()
        
        print(f"ðŸ” Buscando archivo: {file_id}")
        print(f"ðŸ“Š Storage actual: {len(self.storage)} archivos")
        
        if file_id not in self.storage:
            print(f"âŒ Archivo no encontrado: {file_id}")
            print(f"ðŸ“‹ IDs disponibles: {list(self.storage.keys())}")
            
            # âœ… ÃšLTIMA OPORTUNIDAD: Resincronizar por si acaso
            print(f"ðŸ”„ Resincronizando storage por archivo faltante...")
            self._load_and_sync_storage()
            
            if file_id not in self.storage:
                print(f"âŒ Archivo definitivamente no encontrado despuÃ©s de resincronizar")
                return None
            
        info = self.storage[file_id]
        file_path = info.get("path", "")
        
        print(f"ðŸ“„ Archivo encontrado: {info.get('original_name', 'N/A')}")
        
        # âœ… VERIFICACIÃ“N FINAL DE EXISTENCIA FÃSICA
        if file_path and os.path.exists(file_path):
            print(f"âœ… Archivo fÃ­sico confirmado")
            return info
        else:
            print(f"âŒ Archivo fÃ­sico no encontrado, eliminando del storage: {file_path}")
            del self.storage[file_id]
            self._save_storage()
            return None
    
    def cache_dataframe(self, cache_key: str, df: pd.DataFrame):
        """Cachea un DataFrame"""
        self.data_cache[cache_key] = df.copy()
    
    def get_cached_dataframe(self, cache_key: str) -> Optional[pd.DataFrame]:
        """Obtiene DataFrame del cache"""
        return self.data_cache.get(cache_key)
    
    def update_cached_dataframe(self, cache_key: str, df: pd.DataFrame):
        """Actualiza DataFrame en cache"""
        self.data_cache[cache_key] = df
    
    def remove_file(self, file_id: str) -> bool:
        """Remueve archivo del almacenamiento, cache Y archivo fÃ­sico"""
        # âœ… CARGAR STORAGE SI ESTÃ VACÃO
        if not self.storage:
            self._load_and_sync_storage()
            
        if file_id not in self.storage:
            print(f"âš ï¸ Archivo no encontrado en storage para eliminar: {file_id}")
            return False
        
        file_info = self.storage[file_id]
        file_path = file_info.get("path", "")
        
        # âœ… ELIMINAR ARCHIVO FÃSICO
        try:
            if file_path and os.path.exists(file_path):
                os.remove(file_path)
                print(f"ðŸ—‘ï¸ Archivo fÃ­sico eliminado: {file_path}")
        except Exception as e:
            print(f"âš ï¸ Error eliminando archivo fÃ­sico: {e}")
        
        # âœ… LIMPIAR CACHE EN MEMORIA
        cache_keys_to_remove = [key for key in self.data_cache.keys() 
                               if key.startswith(file_id)]
        for key in cache_keys_to_remove:
            del self.data_cache[key]
        
        # âœ… ELIMINAR DEL STORAGE Y GUARDAR JSON
        del self.storage[file_id]
        self._save_storage()
        
        print(f"ðŸ—‘ï¸ Archivo eliminado completamente: {file_info.get('original_name', file_id)}")
        print(f"ðŸ“Š Storage restante: {len(self.storage)} archivos")
        
        return True
    
    def get_all_files(self) -> Dict[str, Dict[str, Any]]:
        """Obtiene todos los archivos almacenados con sincronizaciÃ³n"""
        if not self.storage:
            self._load_and_sync_storage()
        
        print(f"ðŸ“Š Devolviendo {len(self.storage)} archivos sincronizados")
        return self.storage.copy()
    
    def generate_cache_key(self, file_id: str, sheet_name: str = None) -> str:
        """Genera clave para cache"""
        return f"{file_id}_{sheet_name}" if sheet_name else file_id
    
    def cleanup_storage(self):
        """MÃ©todo manual para limpiar storage si es necesario"""
        print(f"ðŸ§¹ Ejecutando limpieza manual del storage...")
        self._load_and_sync_storage()
        return len(self.storage)
storage_manager = FileStorageManager()